{"id": "skfolio.skfolio.utils.stats.n_bins_freedman", "project": "skfolio", "func": "n_bins_freedman", "origin_file": "skfolio/utils/stats.py", "test_list": ["tests/test_utils/test_stats.py"], "prob_info": {"func_start_lineno": 59, "func_end_lineno": 85, "key_block_start_lineno": 79, "key_block_end_lineno": 85, "new_func_code": "def n_bins_freedman(x: np.ndarray) -> int:\n    \"\"\"Compute the optimal histogram bin size using the Freedman-Diaconis rule [1]_.\n\n    Parameters\n    ----------\n    x : ndarray of shape (n_observations,)\n        The input array.\n\n    Returns\n    -------\n    n_bins : int\n        The optimal bin size.\n\n    References\n    ----------\n    .. [1] \"On the histogram as a density estimator: L2 theory\".\n        Freedman & Diaconis (1981).\n    \"\"\"\n    if x.ndim != 1:\n        raise ValueError(\"`x` must be a 1d-array\")\n# 本段代码的功能解释：\n#1. **目的**  \n#    计算输入一维数组 `x` 的最佳直方图分箱数（bin数），依据Freedman-Diaconis规则，衡量分布的分散程度来动态确定分箱数量。本代码块在函数`n_bins_freedman`中，用于根据输入数据自动决定直方图的分箱个数。\n#\n#2. **逻辑**  \n#    - 首先计算输入数组 `x` 的长度，赋值给 `n`。\n#    - 计算`x`的25百分位数（`p_25`）和75百分位数（`p_75`）。\n#    - 计算分箱宽度 `d`，其公式为：  \n#      $$\n#      d = \\frac{2 \\times (p\\_75 - p\\_25)}{n^{1/3}}\n#      $$\n#    - 若分箱宽度 `d` 等于0（即全部数据点集中，很难分箱），则直接返回5个分箱作为默认值。\n#    - 否则，使用如下公式计算分箱数量 `n_bins`：  \n#      $$\n#      n\\_bins = \\max\\left(1, \\lceil \\frac{\\max(x) - \\min(x)}{d} \\rceil \\right)\n#      $$\n#      其中 $\\lceil\\cdot\\rceil$ 表示向上取整。\n#    - 返回 `n_bins` 的四舍五入整数结果。\n#\n#    各分支说明：\n#    - `if d == 0:`  \n#      若分箱宽度为零，说明数据无变异性，返回5。\n#    - 否则，依据Freedman-Diaconis公式动态计算分箱数。\n#\n#3. **异常**  \n#    无\n#\n#4. **变量赋值**\n#    - `n`：表示输入数组 `x` 的长度，即样本数量。\n#    - `p_25`：`x` 的第25百分位数，用于量度数据分布的下四分位。\n#    - `p_75`：`x` 的第75百分位数，用于量度数据分布的上四分位。\n#    - `d`：Freedman-Diaconis规则定义的推荐分箱宽度，代表分布的离散程度。\n#    - `n_bins`：最终建议的直方图分箱数，保证至少为1，并根据数据范围及分箱宽度确定其值。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 37}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.stats.n_bins_knuth", "project": "skfolio", "func": "n_bins_knuth", "origin_file": "skfolio/utils/stats.py", "test_list": ["tests/test_utils/test_stats.py"], "prob_info": {"func_start_lineno": 88, "func_end_lineno": 125, "key_block_start_lineno": 109, "key_block_end_lineno": 124, "new_func_code": "def n_bins_knuth(x: np.ndarray) -> int:\n    \"\"\"Compute the optimal histogram bin size using Knuth's rule [1]_.\n\n    Parameters\n    ----------\n    x : ndarray of shape (n_observations,)\n        The input array.\n\n    Returns\n    -------\n    n_bins : int\n        The optimal bin size.\n\n    References\n    ----------\n    .. [1] \"Optimal Data-Based Binning for Histograms\".\n        Knuth.\n    \"\"\"\n    x = np.sort(x)\n    n = len(x)\n\n# 本段代码的功能解释：\n#1. **目的**  \n#    通过Knuth方法计算最优的直方图分箱数。该代码块定义了一个优化目标函数`func`，并用scipy的优化器对其进行最小化，以确定对于数据`x`而言最优的分箱数`n_bins`，此过程用于改进直方图的表现。\n#\n#2. **逻辑**  \n#    - `func(y: np.ndarray) -> float`为待最小化的目标函数，y为分箱数的候选值（以一维数组形式传入）。  \n#    - `y = y[0]`提取实际的候选值。\n#    - 条件分支：  \n#        - `if y <= 0:`若分箱数非正，返回`np.inf`，使其在最小化过程中被排除。  \n#    - 主体计算部分：  \n#        - 生成等距分箱边界`bin_edges = np.linspace(x[0], x[-1], int(y) + 1)`。\n#        - 计算各分箱内元素个数`hist, _ = np.histogram(x, bin_edges)`。\n#        - 计算Knuth方法下的目标值，公式为：  \n#        \\[\n#        - \\left [ n \\log(y) + \\text{gammaln}(0.5y) - y \\cdot \\text{gammaln}(0.5) - \\text{gammaln}(n + 0.5y) + \\sum \\text{gammaln}(hist + 0.5) \\right ]\n#        \\]\n#        - 该式用于衡量y作为分箱数的优劣。\n#    - 初始分箱数`n_bins_init`通过`n_bins_freedman(x)`获得。\n#    - 用`sco.fmin(func, n_bins_init, disp=0)[0]`对`func`进行无约束最小化，得到最优分箱数`n_bins`。\n#\n#3. **异常**  \n#    无\n#\n#4. **变量赋值**  \n#    - `n_bins_init`：利用Freedman-Diaconis规则根据数组`x`初步估计的分箱数，用作Knuth法优化的起点。\n#    - `n_bins`：应用Knuth方法，通过优化目标函数`func`获得的最优分箱数，最终用于直方图分箱。\n<complete code here>\n    return round(n_bins)", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 37}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.stats.cov_nearest", "project": "skfolio", "func": "cov_nearest", "origin_file": "skfolio/utils/stats.py", "test_list": ["tests/test_utils/test_stats.py"], "prob_info": {"func_start_lineno": 308, "func_end_lineno": 400, "key_block_start_lineno": 377, "key_block_end_lineno": 398, "new_func_code": "def cov_nearest(\n    cov: np.ndarray,\n    higham: bool = False,\n    higham_max_iteration: int = 100,\n    warn: bool = False,\n):\n    \"\"\"Compute the nearest covariance matrix that is positive definite and with a\n    cholesky decomposition than can be computed. The variance is left unchanged.\n    A covariance matrix that is not positive definite often occurs in high\n    dimensional problems. It can be due to multicollinearity, floating-point\n    inaccuracies, or when the number of observations is smaller than the number of\n    assets.\n\n    First, it converts the covariance matrix to a correlation matrix.\n    Then, it finds the nearest correlation matrix and converts it back to a covariance\n    matrix using the initial standard deviation.\n\n    Cholesky decomposition can fail for symmetric positive definite (SPD) matrix due\n    to floating point error and inversely, Cholesky decomposition can success for\n    non-SPD matrix. Therefore, we need to test for both. We always start by testing\n    for Cholesky decomposition which is significantly faster than checking for positive\n    eigenvalues.\n\n    Parameters\n    ----------\n    cov : ndarray of shape (n, n)\n        Covariance matrix.\n\n    higham : bool, default=False\n        If this is set to True, the Higham & Nick (2002) algorithm [1]_ is used,\n        otherwise the eigenvalues are clipped to threshold above zeros (1e-13).\n        The default (`False`) is to use the clipping method as the Higham & Nick\n        algorithm can be slow for large datasets.\n\n    higham_max_iteration : int, default=100\n        Maximum number of iteration of the Higham & Nick (2002) algorithm.\n        The default value is `100`.\n\n    warn : bool, default=False\n        If this is set to True, a user warning is emitted when the covariance matrix\n        is not positive definite and replaced by the nearest. The default is False.\n\n    Returns\n    -------\n    cov : ndarray\n        The nearest covariance matrix.\n\n    References\n    ----------\n    .. [1] \"Computing the nearest correlation matrix - a problem from finance\"\n        IMA Journal of Numerical Analysis\n        Higham & Nick (2002)\n    \"\"\"\n    assert_is_square(cov)\n    assert_is_symmetric(cov)\n\n    # Around 100 times faster than checking eigenvalues with np.linalg.eigh\n    if is_cholesky_dec(cov) and is_positive_definite(cov):\n        return cov\n\n    if warn:\n        warnings.warn(\n            \"The covariance matrix is not positive definite. \"\n            f\"The {'Higham' if higham else 'Clipping'} algorithm will be used to find \"\n            \"the nearest positive definite covariance.\",\n            stacklevel=2,\n        )\n    corr, std = cov_to_corr(cov)\n\n# 本段代码的功能解释：\n#1. **目的**  \n#    该代码块旨在根据输入参数`higham`的不同，修正相关矩阵`corr`（由输入协方差矩阵转换而来）以确保最终生成的协方差矩阵`cov`是正定并可Cholesky分解。主要在`cov_nearest`函数中用于找到“最近似”的正定协方差矩阵。\n#\n#2. **逻辑**  \n#    - 当`higham`为True时，采用Higham & Nick (2002)算法迭代调整相关矩阵：\n#        1. 设定极小数`eps`为`np.finfo(np.float64).eps * 5`用于提升对最小特征值的下限约束。\n#        2. 初始化`diff`为零矩阵，`x`为当前相关矩阵的副本。\n#        3. 在`higham_max_iteration`限定的迭代次数内：\n#            - 计算调整后的矩阵`x_adj = x - diff`。\n#            - 对`x_adj`做特征分解，得到特征值`eig_vals`和特征向量`eig_vecs`。\n#            - 使用以下公式重组`x`矩阵，确保所有特征值大于等于`eps`：\n#              ```math\n#              x = eig\\_vecs * \\max(eig\\_vals, eps) @ eig\\_vecs^T\n#              ```\n#            - 更新`diff = x - x_adj`，用于迭代中的“矫正”。\n#            - 用`np.fill_diagonal(x, 1)`设对角线为1，保证是相关矩阵形式。\n#            - 用`corr_to_cov(x, std)`恢复协方差矩阵。\n#            - 若当前`cov`可Cholesky分解且正定，则退出循环。\n#        4. 若循环结束后仍未找到合格矩阵，则抛出异常。\n#    - 当`higham`为False时，采用简单的特征值裁剪法：\n#        1. 对相关矩阵做特征分解，获得`eig_vals`和`eig_vecs`。\n#        2. 以`_CLIPPING_VALUE=1e-13`为下限对特征值执行裁剪，重算`sqrt`相关矩阵：\n#            ```math\n#            x = eig\\_vecs * \\max(eig\\_vals, \\_CLIPPING\\_VALUE) @ eig\\_vecs^T\n#            ```\n#        3. 调用`cov_to_corr(x)`再次标准化`x`为相关矩阵（有些特征值裁剪后会产生偏差），忽略第二返回值。\n#        4. 用`corr_to_cov(x, std)`计算最终协方差矩阵`cov`。\n#\n#3. **异常**  \n#    - `ValueError`：当采用Higham算法时，迭代`higham_max_iteration`次后仍无法找到正定且可Cholesky分解的相关矩阵时，抛出该异常，内容为\"Unable to find the nearest positive definite matrix\"。\n#    - 当为裁剪法（`higham=False`）时无异常抛出。\n#\n#4. **变量赋值**\n#    - `eps`：极小特征值下限，防止特征值收敛到0以下，避免数值不稳定，仅Higham分支用到。\n#    - `diff`：用于Higham算法的“修正量”矩阵，跟踪与前次调整的偏差。\n#    - `x`：正在迭代调整的相关矩阵候选，每次保证其特征值不低于阈值、对角线为1。\n#    - `cov`：最终得到、可用的正定协方差矩阵，满足正定性与可Cholesky分解性，是本代码块的最终产出。\n<complete code here>\n\n    return cov", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 37}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.stats.commutation_matrix", "project": "skfolio", "func": "commutation_matrix", "origin_file": "skfolio/utils/stats.py", "test_list": ["tests/test_utils/test_stats.py"], "prob_info": {"func_start_lineno": 403, "func_end_lineno": 421, "key_block_start_lineno": 416, "key_block_end_lineno": 420, "new_func_code": "def commutation_matrix(x):\n    \"\"\"Compute the commutation matrix.\n\n    Parameters\n    ----------\n    x : ndarray of shape (n,  m)\n        The matrix.\n\n    Returns\n    -------\n    K : ndarray of shape (m * n, m * n)\n        The commutation matrix.\n    \"\"\"\n# 本段代码的功能解释：\n#1. **目的**  \n#    该代码块的主要目标是根据输入矩阵`x`的形状，生成并返回一个与`x`对应的换位（转置）变换所需的置换稀疏矩阵（commutation matrix）。在当前函数`commutation_matrix`中，此代码块构造了$(m \\times n)$大小矩阵的置换矩阵$K$，即对$\\mathrm{vec}(A)$与$\\mathrm{vec}(A^T)$的变换关系。\n#\n#2. **逻辑**  \n#    - 首先通过`x.shape`获取矩阵`x`的行数`m`和列数`n`。\n#    - 创建一个包含$0,1,...,m*n-1$的整数数组`row`，其长度为$m*n$。\n#    - `col`通过将`row`首先以Fortran列优先方式重塑为$(m, n)$，再按行优先展开成一维。这样，`col`表示矩阵转置时元素在向量化中的索引位置映射。\n#    - 创建全1的数组`data`，长度为$m*n$，类型为`np.int8`。该数组作为稀疏矩阵的非零元素值。\n#    - 通过`csr_matrix((data, (row, col)), shape=(m * n, m * n))`，构建稀疏置换矩阵`k`，其大小为$(m*n, m*n)$。该矩阵实现了对应位置的换位操作。\n#\n#    数学公式表达：\n#    - 置换矩阵$K$的定义满足$\\mathrm{vec}(A^T) = K \\cdot \\mathrm{vec}(A)$，其中$A$为$(m, n)$矩阵。\n#\n#3. **异常**  \n#    无\n#\n#4. **变量赋值**  \n#    - `m`：输入矩阵`x`的行数。\n#    - `n`：输入矩阵`x`的列数。\n#    - `row`：长度为$m*n$的一维数组，表示稀疏矩阵行索引（逐元素编号）。\n#    - `col`：长度为$m*n$的一维数组，表示稀疏矩阵列索引（按转置后元素编号排列）。\n#    - `data`：长度为$m*n$的一维全1数组，作为稀疏矩阵的非零元素值。\n#    - `k`：大小为$(m*n, m*n)$的稀疏置换矩阵，实现$\\mathrm{vec}(A^T) = k \\cdot \\mathrm{vec}(A)$的变换。\n<complete code here>\n    return k", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 37}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.stats.compute_optimal_n_clusters", "project": "skfolio", "func": "compute_optimal_n_clusters", "origin_file": "skfolio/utils/stats.py", "test_list": ["tests/test_utils/test_stats.py"], "prob_info": {"func_start_lineno": 424, "func_end_lineno": 493, "key_block_start_lineno": 477, "key_block_end_lineno": 487, "new_func_code": "def compute_optimal_n_clusters(distance: np.ndarray, linkage_matrix: np.ndarray) -> int:\n    r\"\"\"Compute the optimal number of clusters based on Two-Order Difference to Gap\n    Statistic [1]_.\n\n    The Two-Order Difference to Gap Statistic has been developed to improve the\n    performance and stability of the Tibshiranis Gap statistic.\n    It applies the two-order difference of the within-cluster dispersion to replace the\n    reference null distribution in the Gap statistic.\n\n    The number of cluster :math:`k` is determined by:\n\n    .. math::  \\begin{cases}\n                \\begin{aligned}\n                &\\max_{k} & & W_{k+2} + W_{k} - 2 W_{k+1} \\\\\n                &\\text{s.t.} & & 1 \\ge c \\ge max\\bigl(8, \\sqrt{n}\\bigr) \\\\\n                \\end{aligned}\n                \\end{cases}\n\n    with :math:`n` the sample size and :math:`W_{k}` the within-cluster dispersions\n    defined as:\n\n    .. math:: W_{k} = \\sum_{i=1}^{k} \\frac{D_{i}}{2|C_{i}|}\n\n    where :math:`|C_{i}|` is the cardinality of cluster :math:`i` and :math:`D_{i}` its\n    density defined as:\n\n    .. math:: D_{i} = \\sum_{u \\in C_{i}} \\sum_{v \\in C_{i}} d(u,v)\n\n    with :math:`d(u,v)` the distance between u and v.\n\n\n    Parameters\n    ----------\n    distance : ndarray of shape (n, n)\n        Distance matrix.\n\n    linkage_matrix : ndarray of shape (n - 1, 4)\n        Linkage matrix.\n\n    Returns\n    -------\n    value : int\n        Optimal number of clusters.\n\n    References\n    ----------\n    .. [1] \"Application of two-order difference to gap statistic\".\n        Yue, Wang & Wei (2009)\n    \"\"\"\n    cut_tree = sch.cut_tree(linkage_matrix)\n    n = cut_tree.shape[1]\n    max_clusters = min(n, max(8, round(np.sqrt(n))))\n    dispersion = []\n# 本段代码的功能解释：\n#1. **目的**  \n#    计算不同聚类数下的“组内离散度”（within-cluster dispersion），用于后续判断最优聚类数。该代码块在`compute_optimal_n_clusters`函数中负责：对于每一个可能的聚类数，对所有聚类分别计算组内成员距离的均值，并累加得到总的离散度，将结果记录在`dispersion`列表中。\n#\n#2. **逻辑**  \n#    - 外层循环：`for k in range(max_clusters)`  \n#      - 依次尝试每种可能的聚类数（从1到`max_clusters`），每次聚类的标签`level`由`cut_tree[:, n - k - 1]`取得。\n#    - 新建`cluster_density`列表，用于记录该聚类方案下所有聚类的“密度”。\n#    - 对于本层每一个聚类：`for i in range(np.max(level) + 1)`  \n#        - 通过`cluster_idx = np.argwhere(level == i).flatten()`取得该聚类中的数据索引。\n#        - 利用`distance`矩阵和`squareform`函数，得到该聚类内部所有两两距离的展开矩阵（除去冗余）。\n#        - 若`cluster_dists`非空，计算其均值（`cluster_dists.mean()`），用`np.nan_to_num`防止nan，并添加到`cluster_density`。\n#    - 累加所有聚类的密度：$\\text{dispersion}_k = \\sum_{i} \\text{cluster\\_density}_i$，并存入`dispersion`列表。\n#\n#3. **异常**  \n#    无\n#\n#4. **变量赋值**  \n#    - `level`：当前聚类方案中每个样本所属的聚类标签（对每一个k）。\n#    - `cluster_density`：当前聚类方案下所有聚类组的密度（每组均值）组成的列表。\n#    - `cluster_idx`：当前聚类标签i下的成员索引。\n#    - `cluster_dists`：当前聚类中成员两两之间的距离矩阵（压缩后形式）。\n#    - `dispersion`：记录每个聚类数k下，所有聚类内密度之和的列表，用于后续最优聚类数的判别。\n<complete code here>\n    dispersion = np.array(dispersion)\n    gaps = np.roll(dispersion, -2) + dispersion - 2 * np.roll(dispersion, -1)\n    gaps = gaps[:-2]\n    # k=0 represents one cluster\n    k = np.argmax(gaps) + 2\n    return k", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 37}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.stats.rand_weights", "project": "skfolio", "func": "rand_weights", "origin_file": "skfolio/utils/stats.py", "test_list": ["tests/test_utils/test_stats.py"], "prob_info": {"func_start_lineno": 145, "func_end_lineno": 166, "key_block_start_lineno": 162, "key_block_end_lineno": 166, "new_func_code": "def rand_weights(n: int, zeros: int = 0) -> np.array:\n    \"\"\"Produces n random weights that sum to one from an uniform distribution\n    (non-uniform distribution over a simplex).\n\n    Parameters\n    ----------\n    n : int\n        Number of weights.\n\n    zeros : int, default=0\n        The number of weights to randomly set to zeros.\n\n    Returns\n    -------\n    weights : ndarray of shape (n, )\n        The vector of weights.\n    \"\"\"\n# 本段代码的功能解释：\n#1. **目的**  \n#    该代码块的主要目标是在长度为`n`的向量中生成一组随机权重，这些权重的和为1，并允许指定其中有多少个权重被设为0。该代码块作为`rand_weights`函数的核心部分，负责生成最终的“随机带零权重向量”。\n#\n#2. **逻辑**  \n#    - 首先，通过调用`np.random.rand(n)`生成一个包含`n`个[0,1)区间均匀分布随机数的一维数组，赋值给变量`k`。\n#    - 然后，如果`zeros > 0`（即需要设置为0的权重个数大于0）：\n#        - 使用`np.random.choice(n, zeros, replace=False)`随机选择`n`个索引中的`zeros`个索引（不重复），将结果赋值给`zeros_idx`。\n#        - 将`k`中`zeros_idx`对应位置的元素设为0。\n#    - 最后，将数组`k`除以其元素之和（`sum(k)`），实现归一化，使所有元素加和为1，并返回该归一化后的数组。\n#    - 归一化公式为：  \n#      $$k = k / \\sum k$$\n#      其中$\\sum k$是归零处理后的`k`的和。\n#\n#3. **异常**  \n#    无。\n#\n#4. **变量赋值**\n#    - `k`：存储生成的n个[0,1)之间的随机权重，若`zeros > 0`还会有`zeros`个元素被随机置为0，最后归一化后即为输出的权重向量。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 37}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.stats.minimize_relative_weight_deviation", "project": "skfolio", "func": "minimize_relative_weight_deviation", "origin_file": "skfolio/utils/stats.py", "test_list": ["tests/test_utils/test_stats.py"], "prob_info": {"func_start_lineno": 496, "func_end_lineno": 577, "key_block_start_lineno": 557, "key_block_end_lineno": 577, "new_func_code": "def minimize_relative_weight_deviation(\n    weights: np.ndarray,\n    min_weights: np.ndarray,\n    max_weights: np.ndarray,\n    solver: str = \"CLARABEL\",\n    solver_params: dict | None = None,\n) -> np.ndarray:\n    r\"\"\"\n    Apply weight constraints to an initial array of weights by minimizing the relative\n    weight deviation of the final weights from the initial weights.\n\n    .. math::\n            \\begin{cases}\n            \\begin{aligned}\n            &\\min_{w} & & \\Vert \\frac{w - w_{init}}{w_{init}} \\Vert_{2}^{2} \\\\\n            &\\text{s.t.} & & \\sum_{i=1}^{N} w_{i} = 1 \\\\\n            & & & w_{min} \\leq w_i \\leq w_{max}, \\quad \\forall i\n            \\end{aligned}\n            \\end{cases}\n\n    Parameters\n    ----------\n    weights : ndarray of shape (n_assets,)\n        Initial weights.\n\n    min_weights : ndarray of shape (n_assets,)\n        Minimum assets weights (weights lower bounds).\n\n    max_weights : ndarray of shape (n_assets,)\n        Maximum assets weights (weights upper bounds).\n\n    solver : str, default=\"CLARABEL\"\n        The solver to use. The default is \"CLARABEL\" which is written in Rust and has\n        better numerical stability and performance than ECOS and SCS.\n        For more details about available solvers, check the CVXPY documentation:\n        https://www.cvxpy.org/tutorial/advanced/index.html#choosing-a-solver\n\n    solver_params : dict, optional\n        Solver parameters. For example, `solver_params=dict(verbose=True)`.\n        The default (`None`) is to use the CVXPY default.\n        For more details about solver arguments, check the CVXPY documentation:\n        https://www.cvxpy.org/tutorial/advanced/index.html#setting-solver-options\n    \"\"\"\n    if not (weights.shape == min_weights.shape == max_weights.shape):\n        raise ValueError(\"`min_weights` and `max_weights` must have same size\")\n\n    if np.any(weights < 0):\n        raise ValueError(\"Initial weights must be strictly positive\")\n\n    if not np.isclose(np.sum(weights), 1.0):\n        raise ValueError(\"Initial weights must sum to one\")\n\n    if np.any(max_weights < min_weights):\n        raise ValueError(\"`min_weights` must be lower or equal to `max_weights`\")\n\n    if np.all((weights >= min_weights) & (weights <= max_weights)):\n        return weights\n\n    if solver_params is None:\n        solver_params = {}\n\n# 本段代码的功能解释：\n#1. **目的**  \n#    求解满足给定约束条件（权重和为1，且在指定下限`min_weights`和上限`max_weights`之间）的权重向量，使得其与初始权重`weights`的相对偏离程度最小。该代码块在当前函数中负责建立、求解优化问题，并在失败时处理异常，最终返回优化得到的新权重。\n#\n#2. **逻辑**  \n#    - 首先，定义变量数量`n = len(weights)`，并创建一个长度为n的cvxpy优化变量`w`。\n#    - 定义目标函数为`cp.Minimize(cp.norm(w / weights - 1))`，即最小化变量`w`与初始权重`weights`之间的相对变化的二范数：  \n#      $$\n#      \\min_{w} \\|\\frac{w}{weights} - 1\\|_2\n#      $$\n#    - 约束条件包括：\n#        1. $\\sum_i w_i = 1$，即权重之和为1；\n#        2. $w_i \\geq min\\_weights_i$，每个权重下界；\n#        3. $w_i \\leq max\\_weights_i$，每个权重上界。\n#    - 创建cvxpy问题：  \n#      ```\n#      problem = cp.Problem(objective, constraints)\n#      ```\n#    - 使用`problem.solve(solver=solver, **solver_params)`求解优化问题。\n#    - 检查`w.value`是否为None（即无可行解），若无，则抛出`cp.SolverError(\"No solution found\")`。\n#    - 如果求解过程中抛出了`cp.SolverError`或`scl.ArpackNoConvergence`异常，则重新抛出`cp.SolverError`，提示更换solver或增加调试信息。\n#    - 最后，返回优化后的权重`w.value`。\n#\n#3. **异常**\n#    - `cp.SolverError`：在以下情况抛出\n#        - 优化求解器没有找到任何解（`w.value is None`）。\n#        - 优化器（cvxpy的solver）或稀疏线性代数库(scipy.sparse.linalg)求解失败或未收敛时（捕获`cp.SolverError`和`scl.ArpackNoConvergence`）。\n#    - 其他异常无处理。\n#\n#4. **变量赋值**\n#    - `w`：cvxpy中的优化变量，代表最终优化得到的新权重向量。其解（`w.value`）是满足约束条件、与原始权重相对偏离最小的权重分配，用于替代原始权重。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 37}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.equations._split_equation_string", "project": "skfolio", "func": "_split_equation_string", "origin_file": "skfolio/utils/equations.py", "test_list": ["tests/test_utils/test_equations.py"], "prob_info": {"func_start_lineno": 347, "func_end_lineno": 371, "key_block_start_lineno": 350, "key_block_end_lineno": 364, "new_func_code": "def _split_equation_string(string: str) -> list[str]:\n    \"\"\"Split an equation strings by operators.\"\"\"\n    comp_pattern = \"(?=\" + \"|\".join([\".+\\\\\" + e for e in _COMPARISON_OPERATORS]) + \")\"\n# 本段代码的功能解释：\n#1. **目的**  \n#    检查输入的方程字符串`string`中是否包含有效的比较运算符（`==`, `=`, `<=`, `>=`），并进一步校验字符串中未出现不被支持的单独`'>'`或`'<'`运算符。若检查失败，则抛出异常提示错误原因。该代码块在`_split_equation_string`函数中，用于确保传入的字符串格式合法，可被后续分割和解析。\n#\n#2. **逻辑**  \n#    - 首先用正则表达式`comp_pattern`匹配输入的`string`，检查其是否至少包含一个合法的比较运算符（即`==`, `=`, `<=`, `>=`）。如果没有匹配上，则说明该字符串不是一个包含比较关系的等式，会抛出`EquationToMatrixError`异常。\n#    - 紧接着定义`invalid_pattern`，用于检测字符串中是否存在错误的比较运算符，即只包含单独的`'>'`或`'<'`，而不是`'>='`或`'<='`。利用`re.findall`检索所有不被允许的运算符。如果`invalid_matches`列表非空，说明存在非法的比较运算符（如单独的`'>'`），则抛出`EquationToMatrixError`异常，并提示最先检测到的非法运算符。\n#\n#3. **异常**  \n#    - `EquationToMatrixError`：  \n#      - 若字符串中不包含任何有效的比较运算符（`==`, `=`, `<=`, `>=`）时抛出。  \n#      - 若字符串中出现了不被允许的单独`'>'`或`'<'`运算符时抛出。\n#\n#4. **变量赋值**  \n#    无（本代码块不涉及变量的赋值或修改，仅校验与异常处理）。\n<complete code here>\n\n    # '==' needs to be before '='\n    operators = sorted(_OPERATORS, reverse=True)\n    pattern = \"((?:\" + \"|\".join([\"\\\\\" + e for e in operators]) + \"))\"\n    res = [x.strip() for x in re.split(pattern, string)]\n    res = [x for x in res if x != \"\"]\n    return res", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 12}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.equations._string_to_equation", "project": "skfolio", "func": "_string_to_equation", "origin_file": "skfolio/utils/equations.py", "test_list": ["tests/test_utils/test_equations.py"], "prob_info": {"func_start_lineno": 374, "func_end_lineno": 499, "key_block_start_lineno": 447, "key_block_end_lineno": 494, "new_func_code": "def _string_to_equation(\n    groups: np.ndarray,\n    string: str,\n    sum_to_one: bool,\n) -> tuple[np.ndarray, float, bool]:\n    \"\"\"Convert a string to a left 1D-array and right float of the form:\n    `groups @ left <= right` or `groups @ left == right` and return whether it's an\n    equality or inequality.\n\n    Parameters\n    ----------\n    groups : ndarray of shape (n_groups, n_assets)\n        Groups 2D-array\n\n    string : str\n        String to convert\n\n    sum_to_one : bool\n        If this is set to True, the 1D-array is scaled to have a sum of one.\n\n    Returns\n    -------\n    left : 1D-array of shape (n_assets,)\n    right : float\n    is_inequality : bool\n    \"\"\"\n    n = groups.shape[1]\n    err_msg = f\"Wrong pattern encountered while converting the string '{string}'\"\n\n    iterator = iter(_split_equation_string(string))\n    group_names = set(groups.flatten())\n\n    def is_group(name: str) -> bool:\n        return name in group_names\n\n    left = np.zeros(n)\n    right = 0\n    main_sign = 1\n    comparison_sign = None\n    is_inequality = None\n    e = next(iterator, None)\n    i = 0\n    while True:\n        i += 1\n        if i > 1e6:\n            raise RecursionError(err_msg)\n        if e is None:\n            break\n        sign = 1\n        if e in _COMPARISON_OPERATORS:\n            if e in _INEQUALITY_OPERATORS:\n                is_inequality = True\n            else:\n                is_inequality = False\n            main_sign = -1\n            comparison_sign = _comparison_operator_sign(e)\n            e = next(iterator, None)\n            if e in _SUB_ADD_OPERATORS:\n                sign *= _sub_add_operator_sign(e)\n                e = next(iterator, None)\n        elif e in _SUB_ADD_OPERATORS:\n            sign *= _sub_add_operator_sign(e)\n            e = next(iterator, None)\n        elif e in _MUL_OPERATORS:\n            raise EquationToMatrixError(\n                f\"{err_msg}: the character '{e}' is wrongly positioned\"\n            )\n        sign *= main_sign\n        # next can only be a number or a group\n        if e is None or e in _OPERATORS:\n            raise EquationToMatrixError(\n                f\"{err_msg}: the character '{e}' is wrongly positioned\"\n            )\n# 本段代码的功能解释：\n#1. **目的**  \n#    解析线性方程（字符串）中的一个语法单元（可能为组名或数字），并根据后续的操作符与元素适当地将相应的值加到`left`或`right`。该逻辑块负责在递归主循环内处理每一段拆分的等式字符串，支持如“组名、常数、乘法、加减法”等情形，将文本公式转换为线性代数表达。\n#\n#2. **逻辑**  \n#    - 如果`e`是一个组名（`is_group(e)`为真）：\n#        1. 用`_matching_array(values=groups, key=e, sum_to_one=sum_to_one)`生成一个与该组名匹配的一维数组`arr`。\n#        2. 下一个元素`e = next(iterator, None)`，分支判断：\n#            - 若`e`为`None`或在`_NON_MUL_OPERATORS`（如'+', '-', '>=', '==', '<=', '='），直接有  \n#              ```math\n#              \\text{left} \\mathrel{+}= \\text{sign} \\times \\text{arr}\n#              ```\n#            - 若`e`为乘法符号（`in _MUL_OPERATORS`），则下一个`e`必须为数字：  \n#                - 尝试将`e`转换为float类型，若失败则抛出`GroupNotFoundError`。\n#                - 否则有  \n#                  ```math\n#                  \\text{left} \\mathrel{+}= \\text{number} \\times \\text{sign} \\times \\text{arr}\n#                  ```\n#                - 继续取下一个元素`e = next(iterator, None)`。\n#            - 其他情况，抛出`EquationToMatrixError`异常，说明等式格式不正确。\n#    - 否则（`e`不是组名，应该是数字）：\n#        1. 尝试将`e`转换为float类型，若失败则抛出`GroupNotFoundError`。\n#        2. 下一个元素`e = next(iterator, None)`，分支判断：\n#            - 若`e`是乘法符号（`in _MUL_OPERATORS`），则下一个`e`必须是组名，否则抛出`EquationToMatrixError`。\n#                - 匹配组名后，生成`arr`，有  \n#                  ```math\n#                  \\text{left} \\mathrel{+}= \\text{number} \\times \\text{sign} \\times \\text{arr}\n#                  ```\n#                - 继续取下一个元素`e = next(iterator, None)`。\n#            - 若`e`为`None`或在`_NON_MUL_OPERATORS`，直接有  \n#              ```math\n#              \\text{right} \\mathrel{+}= \\text{number} \\times \\text{sign}\n#              ```\n#            - 其他情况，抛出`EquationToMatrixError`异常。\n#\n#3. **异常**\n#    - `GroupNotFoundError`：当字符串无法转换为float且不属于已知分组时，表示组丢失时抛出。\n#    - `EquationToMatrixError`：当操作符使用不合规范、顺序出错（如不应出现的位置出现了乘号等）时抛出。\n#\n#4. **变量赋值**\n#    - `left`：  \n#      - 增加由当前组或系数与组组合而成的表达式的向量，累计线性方程左侧的各个分量。\n#    - `right`：  \n#      - 累加等式右端单独出现的数值常量，累计线性方程右侧的常数项。\n<complete code here>\n\n    left *= comparison_sign\n    right *= -comparison_sign\n\n    return left, right, is_inequality", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 12}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.equations.equations_to_matrix", "project": "skfolio", "func": "equations_to_matrix", "origin_file": "skfolio/utils/equations.py", "test_list": ["tests/test_utils/test_equations.py"], "prob_info": {"func_start_lineno": 32, "func_end_lineno": 134, "key_block_start_lineno": 112, "key_block_end_lineno": 134, "new_func_code": "def equations_to_matrix(\n    groups: npt.ArrayLike,\n    equations: npt.ArrayLike,\n    sum_to_one: bool = False,\n    raise_if_group_missing: bool = False,\n    names: tuple[str, str] = (\"groups\", \"equations\"),\n) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Convert a list of linear equations into the left and right matrices of the\n    inequality A <= B and equality A == B.\n\n    Parameters\n    ----------\n    groups : array-like of shape (n_groups, n_assets)\n        2D array of assets groups.\n\n        For example:\n\n             groups = np.array(\n                [\n                    [\"SPX\", \"SX5E\", \"NKY\", \"TLT\"],\n                    [\"Equity\", \"Equity\", \"Equity\", \"Bond\"],\n                    [\"US\", \"Europe\", \"Japan\", \"US\"],\n                ]\n            )\n\n    equations : array-like of shape (n_equations,)\n         1D array of equations.\n\n         Example of valid equation patterns:\n            * \"number_1 * group_1 + number_3 <= number_4 * group_3 + number_5\"\n            * \"group_1 == number * group_2\"\n            * \"group_1 <= number\"\n            * \"group_1 == number\"\n\n        \"group_1\" and \"group_2\" are the group names defined in `groups`.\n        The second expression means that the sum of all assets in \"group_1\" should be\n        less or equal to \"number\" times the sum of all assets in \"group_2\".\n\n        For example:\n\n             equations = [\n                \"Equity <= 3 * Bond\",\n                \"US >= 1.5\",\n                \"Europe >= 0.5 * Japan\",\n                \"Japan == 1\",\n                \"3*SPX + 5*SX5E == 2*TLT + 3\",\n            ]\n\n    sum_to_one : bool\n        If this is set to True, all elements in a group sum to one (used in the `views`\n        of the Black-Litterman model).\n\n    raise_if_group_missing : bool, default=False\n        If this is set to True, an error is raised when a group is not found in the\n        groups, otherwise only a warning is shown.\n        The default is False.\n\n    names : tuple[str, str], default=('groups', 'equations')\n        The group and equation names used in error messages.\n        The default is `('groups', 'equations')`.\n\n    Returns\n    -------\n    left_equality: ndarray of shape (n_equations_equality, n_assets)\n    right_equality: ndarray of shape (n_equations_equality,)\n        The left and right matrices of the inequality A <= B.\n\n    left_inequality: ndarray of shape (n_equations_inequality, n_assets)\n    right_inequality: ndarray of shape (n_equations_inequality,)\n        The left and right matrices of the equality A == B.\n    \"\"\"\n    groups = _validate_groups(groups, name=names[0])\n    equations = _validate_equations(equations, name=names[1])\n\n    a_equality = []\n    b_equality = []\n\n    a_inequality = []\n    b_inequality = []\n\n# 本段代码的功能解释：\n#1. **目的**  \n#    对传入的字符串表达式列表（`equations`）进行解析，将每个方程转化为左、右矩阵（分别表示等式和不等式的情形），并将结果累积到相应的列表中，最终返回numpy数组形式的四个矩阵。这一代码块在当前函数中负责遍历所有等式字符串、处理分支，并汇总解析结果。\n#\n#2. **逻辑**  \n#    - 遍历`equations`中的每个字符串`string`。\n#    - 对于每一个`string`，调用`_string_to_equation(groups=groups, string=string, sum_to_one=sum_to_one)`，将字符串解析为左向量`left`、右标量`right`，并判断是否为不等式`is_inequality`。\n#    - 如果`is_inequality`为真，即当前方程是个不等式，则将`left`添加到`a_inequality`，`right`添加到`b_inequality`。\n#    - 否则（即为等式），将`left`添加到`a_equality`，`right`添加到`b_equality`。\n#    - 如果解析过程中抛出`GroupNotFoundError`异常（如某group字符串在`groups`中未找到），则\n#        - 若`raise_if_group_missing`为真，直接重新抛出异常。\n#        - 否则，使用`warnings.warn(str(e), stacklevel=2)`输出警告，继续处理剩余方程。\n#    - 最后，将4个结果列表分别转为numpy数组并返回：\n#        $$\n#        \\text{返回} \\left(\n#            \\text{np.array}(a\\_equality),\\;\\;\n#            \\text{np.array}(b\\_equality),\\;\\;\n#            \\text{np.array}(a\\_inequality),\\;\\;\n#            \\text{np.array}(b\\_inequality)\n#        \\right)\n#        $$\n#\n#3. **异常**\n#    - `GroupNotFoundError`：若在解析某个等式时引用的分组不在`groups`中，抛出该异常。是否传播该异常由`raise_if_group_missing`参数决定。\n#    - 其它异常未被直接捕捉，若`_string_to_equation`内部还会抛出其它异常，则会向上传递。\n#\n#4. **变量赋值**\n#    - `a_equality`：保存解析为等式的所有左侧向量（每个元素为一个针对资产的权重向量）。\n#    - `b_equality`：保存解析为等式的所有右侧标量（每个元素为等式的标量右值）。\n#    - `a_inequality`：保存解析为不等式的所有左侧向量（每个元素为一个针对资产的权重向量）。\n#    - `b_inequality`：保存解析为不等式的所有右侧标量（每个元素为不等式的标量右值）。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 12}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.equations._validate_groups", "project": "skfolio", "func": "_validate_groups", "origin_file": "skfolio/utils/equations.py", "test_list": ["tests/test_utils/test_equations.py"], "prob_info": {"func_start_lineno": 195, "func_end_lineno": 226, "key_block_start_lineno": 210, "key_block_end_lineno": 224, "new_func_code": "def _validate_groups(groups: npt.ArrayLike, name: str = \"groups\") -> np.ndarray:\n    \"\"\"Validate groups by checking its dim and if group names don't appear in multiple\n    levels and convert to numpy array.\n\n    Parameters\n    ----------\n    groups : array-like of shape (n_groups, n_assets)\n        2D-array of strings.\n\n    Returns\n    -------\n    groups : ndarray of shape (n_groups, n_assets)\n        2D-array of strings.\n    \"\"\"\n    groups = np.asarray(groups)\n# 本段代码的功能解释：\n#1. **目的**  \n#    检查并验证输入的`groups`变量为二维数组，且每个组名只能出现在一个层级中，避免组名重复出现在不同的层级（row）里。\n#\n#2. **逻辑**  \n#    - 首先判断`groups.ndim != 2`，即如果`groups`不是二维数组，则抛出`ValueError`，提示输入数组维度错误。\n#    - 计算`n = len(groups)`，即层级数。\n#    - 构建`group_sets`，其中每一项为`groups`每一行（层级）的唯一组名集合。\n#    - 双层循环：  \n#        - 外层遍历第`i`个层级（从0到n-2），内层遍历第`i`层级的每个组名`e`。\n#        - 在更靠后的每个层级`j`（i+1到n-1）中检查是否包含同样的组名`e`。\n#        - 如果某个组名`e`在两个不同层级中都出现，则抛出`DuplicateGroupsError`，并在异常信息中指出具体冲突的组名与层级，提示组名只能属于一个层级。\n#\n#3. **异常**  \n#    - `ValueError`：当`groups`不是二维数组时抛出。\n#    - `DuplicateGroupsError`：当某个组名出现在多个层级中时抛出。\n#\n#4. **变量赋值**  \n#    - `n`：存储`groups`的行数（层级数），用于循环判断。\n#    - `group_sets`：存储每个层级下的组名集合，用于跨层级组名查重。\n<complete code here>\n\n    return groups", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 12}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.equations.group_cardinalities_to_matrix", "project": "skfolio", "func": "group_cardinalities_to_matrix", "origin_file": "skfolio/utils/equations.py", "test_list": ["tests/test_utils/test_equations.py"], "prob_info": {"func_start_lineno": 137, "func_end_lineno": 192, "key_block_start_lineno": 179, "key_block_end_lineno": 192, "new_func_code": "def group_cardinalities_to_matrix(\n    groups: npt.ArrayLike,\n    group_cardinalities: dict[str, int],\n    raise_if_group_missing: bool = False,\n) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Convert a list of linear equations into the left and right matrices of the\n    inequality A <= B and equality A == B.\n\n    Parameters\n    ----------\n    groups : array-like of shape (n_groups, n_assets)\n        2D array of assets groups.\n\n        For example:\n\n             groups = np.array(\n                [\n                    [\"Equity\", \"Equity\", \"Equity\", \"Bond\"],\n                    [\"US\", \"Europe\", \"Japan\", \"US\"],\n                ]\n            )\n\n    group_cardinalities : dict[str, int]\n        Dictionary of cardinality constraint per group.\n        For example: {\"Equity\": 1, \"US\": 3}\n\n    raise_if_group_missing : bool, default=False\n        If this is set to True, an error is raised when a group is not found in the\n        groups, otherwise only a warning is shown.\n        The default is False.\n\n    Returns\n    -------\n    left_inequality: ndarray of shape (n_constraints, n_assets)\n    right_inequality: ndarray of shape (n_constraints,)\n        The left and right matrices of the cardinality inequality.\n    \"\"\"\n    groups = _validate_groups(groups, name=\"group\")\n\n    a_inequality = []\n    b_inequality = []\n\n# 本段代码的功能解释：\n#1. **目的**  \n#    将每个分组名-基数对（`group`, `card`）转化为一元组线性不等式的左、右矩阵表示。其中左侧矩阵用于标记哪些资产属于对应分组，右侧为相应的分组资产数量上限。代码块实现的是基数约束矩阵的构建，为后续优化问题提供结构化输入。\n#\n#2. **逻辑**  \n#    - 遍历`group_cardinalities`中的每个分组`group`及其对应基数上限`card`。  \n#    - 对每一对，调用`_matching_array(values=groups, key=group, sum_to_one=False)`，返回一个一维数组`arr`，其元素对每个资产，如果该资产属于此`group`则为1，否则为0。  \n#    - 将`arr`添加到`a_inequality`列表，`card`添加到`b_inequality`列表。\n#    - **异常处理**：  \n#        - 如果`_matching_array`无法在`groups`中找到`group`，将抛出`GroupNotFoundError`。  \n#        - 如果`raise_if_group_missing`为True，直接向上抛出此异常，否则用`warnings.warn`发出警告。\n#    - 循环结束后，将`a_inequality`和`b_inequality`分别转为numpy数组，作为函数返回值。\n#\n#3. **异常**  \n#    - 当分组`group`未在`groups`中找到时，`_matching_array`抛出`GroupNotFoundError`。  \n#    - 如果`raise_if_group_missing`为True，该异常直接抛出；否则触发一次警告（warnings.warn）。  \n#\n#4. **变量赋值**  \n#    - `a_inequality`：依次收集所有分组的“资产属于该分组”的掩码数组，形成约束左矩阵，每一行为某分组的资产分布。  \n#    - `b_inequality`：依次收集所有分组对应的基数上限（`card`），形成约束右向量，每个值限制相应分组资产的数量上限。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 12}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.bootstrap.stationary_bootstrap", "project": "skfolio", "func": "stationary_bootstrap", "origin_file": "skfolio/utils/bootstrap.py", "test_list": ["tests/test_utils/test_bootstrap.py"], "prob_info": {"func_start_lineno": 68, "func_end_lineno": 118, "key_block_start_lineno": 103, "key_block_end_lineno": 118, "new_func_code": "def stationary_bootstrap(\n    returns: np.ndarray,\n    n_bootstrap_samples: int,\n    block_size: float | None = None,\n    seed: int | None = None,\n) -> np.ndarray:\n    \"\"\"Create `n_bootstrap_samples` samples from a multivariate return series via\n    stationary bootstrapping.\n\n    Parameters\n    ----------\n    returns: ndarray of shape (n_observations, n_assets)\n        The returns array.\n\n    n_bootstrap_samples: int\n        The number of bootstrap samples to generate.\n\n    block_size: float, optional\n        The block size.\n        If this is set to None, we estimate the optimal block size using Politis &\n        White algorithm for all individual asset and the median.\n\n    seed: int, optional\n        Random seed used to initialize the pseudo-random number generator\n\n    Returns\n    -------\n    value: ndarray\n           The sample returns of shape (reps, nb observations, nb assets)\n\n    \"\"\"\n    np.random.seed(seed=seed)\n    n_observations, n_assets = returns.shape\n    x = np.vstack((returns, returns))\n    # Loop over reps bootstraps\n# 本段代码的功能解释：\n#1. **目的**  \n#    本代码块用于根据stationary bootstrap方法生成自助采样（bootstrap）样本的索引矩阵，通过一定区块结构的采样索引，从原始数据`x`中抽取有时序依赖的样本，用于后续统计分析或模型训练。其核心职责是，在给定区块长度控制下，构建每次bootstrap重采样所用的观测索引序列，以体现时间序列数据中的依赖结构。\n#\n#2. **逻辑**  \n#    - 判断`block_size`是否为None：  \n#        - 若为None，则对每个资产（即`returns`的每一列）分别调用`optimal_block_size`，得到每列的最优区块长度，并取它们的中位数赋值给`block_size`。  \n#    - 使用`np.random.randint`生成形状为`(n_bootstrap_samples, n_observations)`的初始索引矩阵`indices`，每个元素为`[0, n_observations)`区间的整数，表示原始样本的行索引。  \n#    - 用`np.random.rand`生成同形状的布尔型矩阵`cond`，`cond[i, j]`为True的条件为：  \n#        $$\n#        \\text{cond}[i, j] = \\text{uniform}(0, 1) \\geq \\frac{1}{\\text{block\\_size}}\n#        $$\n#        这是stationary bootstrap的区块延续判据。  \n#    - 双重循环遍历每个bootstrap重采样和每个观测位置，从第二个观测（$j \\geq 1$）起：  \n#        - 若`cond[i, j]`为True，则：  \n#            $$\n#            \\text{indices}[i, j] = \\text{indices}[i, j-1] + 1\n#            $$\n#            即该位置采样索引为前一个位置基础上加一，表示区块延续。  \n#        - 若为False，则保持原初始化的随机索引，表示区块重新采样起点。  \n#    - 对所有`indices`元素，若其值大于`2 * n_observations`，则将该位置索引置为0：  \n#        $$\n#        \\text{indices}[\\text{indices} > 2 * n\\_observations] = 0\n#        $$\n#        此逻辑的含义是：在区块延续过程中，索引有可能超出原序列长度。将其置0可避免越界错误。选择`2 * n_observations`作为上限主要是为了保证在极端情况下索引不会指向远离样本区间的非法位置，但具体取值是稳健性处理，并非理论要求，目的是保证索引不会溢出原始观测区间。  \n#    - 返回`x[indices, :]`，即按上述生成的索引从原始数据`x`中抽取的自助采样样本。这里`x`为采样数据的实际来源，需保证其与`returns`等价，否则将导致下游数据不一致。\n#\n#3. **异常**  \n#    无\n#\n#4. **变量赋值**\n#    - `block_size`：如传入为None，则计算所有资产收益序列单独的最优区块长度，并取中位数作为整体的区块控制参数。\n#    - `indices`：二维数组，存储所有bootstrap样本在各观测位置对应的原始数据行索引。初值全随机，后续部分位置据stationary bootstrap规则做区块延续处理，若发生越界（大于`2 * n_observations`），则置为0，防止非法索引。\n#    - `cond`：布尔型二维数组，定义每一位置是否与前一区块相连（True则连，否则重新采样）。\n#    - `x`：数据源，实际用于采样的原始矩阵。注意，采样结果来自`x`，本代码逻辑假设其为`returns`的副本或本应与原`returns`一致。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 1}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.tools.input_to_array", "project": "skfolio", "func": "input_to_array", "origin_file": "skfolio/utils/tools.py", "test_list": ["tests/test_utils/test_tools.py"], "prob_info": {"func_start_lineno": 357, "func_end_lineno": 442, "key_block_start_lineno": 398, "key_block_end_lineno": 442, "new_func_code": "def input_to_array(\n    items: dict | npt.ArrayLike,\n    n_assets: int,\n    fill_value: Any,\n    dim: int,\n    assets_names: np.ndarray | None,\n    name: str,\n) -> np.ndarray:\n    \"\"\"Convert a collection of items (array-like or dictionary) into\n    a numpy array and verify its shape.\n\n    Parameters\n    ----------\n    items : np.ndarray | dict | list\n        Items to verify and convert to array.\n\n    n_assets : int\n        Expected number of assets.\n        Used to verify the shape of the converted array.\n\n    fill_value : Any\n        When `items` is a dictionary, elements that are not in `asset_names` are filled\n        with `fill_value` in the converted array.\n\n    dim : int\n        Dimension of the final array.\n        Possible values are `1` or `2`.\n\n    assets_names : ndarray, optional\n        Asset names used when `items` is a dictionary.\n\n    name : str\n        Name of the items used for error messages.\n\n    Returns\n    -------\n    values : ndarray of shape (n_assets) for dim=1 or (n_groups, n_assets) for dim=2\n        Converted array.\n    \"\"\"\n    if dim not in [1, 2]:\n        raise ValueError(f\"dim must be 1 or 2, got {dim}\")\n# 本段代码的功能解释：\n#1. **目的**  \n#    该代码块的目的是将输入的`items`变量（可以是字典、数组或列表）转换为Numpy数组，并对其维度、缺失值和形状等进行严格校验，从而保证下游计算所需的数据输入格式和完整性。其在函数中的职责是作为输入校验及标准化过程的核心部分。\n#\n#2. **逻辑**  \n#    - 首先判断`items`是否为字典类型：\n#        - 若是字典类型，检查`assets_names`不能为空，否则抛出异常。\n#        - 若`dim == 1`，则遍历`assets_names`，用`items.get(asset, fill_value)`为每个资产名称取值；若字典中不存在该资产，则用`fill_value`填充，最终生成一维Numpy数组`arr`。\n#        - 若`dim == 2`，则构建一个字典`arr`，其中每个key为`asset`，value为与资产相关的信息列表。如果该资产在`items`里查不到，则用`[asset]`；若`items[asset]`是标量，则转为`[asset, elem]`；否则假定`elem`为可迭代并拼接为`[asset, *elem]`。随后用`pd.DataFrame.from_dict`将其转换为DataFrame，并按`assets_names`顺序排列，然后转为Numpy数组并转置，得到最终的二维数组`arr`。\n#    - 如果`items`不是字典，则直接用`np.asarray(items)`转为数组。\n#    - 检查`arr`的维度，如果其`ndim`与`dim`要求不符，抛出异常。\n#    - 检查是否有NaN值（前提是`fill_value`不是字符串），若有则抛出异常。\n#    - 检查数组的shape最后一维是否等于`n_assets`，否则按维度要求提示正确shape，并抛出异常。\n#    - 所有校验通过后返回数组`arr`。\n#\n#3. **异常**  \n#    - `ValueError`：  \n#        - 若`assets_names`为`None`且`items`是字典时。\n#        - 若`arr`的维度（`arr.ndim`）与所需`dim`不一致时。\n#        - 若检测到NaN值并且`fill_value`不是字符串时。\n#        - 若`arr`的最后一维大小不等于`n_assets`时。\n#    - 无其它异常被显式抛出。\n#\n#4. **变量赋值**  \n#    - `arr`：  \n#        - 当`items`为dict且`dim==1`时，`arr`为一个一维Numpy数组，每个元素是对应`assets_names`中名称在字典中的值或`fill_value`。\n#        - 当`items`为dict且`dim==2`时，`arr`为二维Numpy数组，每列对应一个资产，其内容取决于字典的value类型与资产名的组合。\n#        - 当`items`不是dict时，`arr`直接为`np.asarray(items)`的结果。\n#        - 经过一系列校验后，`arr`代表了被标准化并校验合格的输入数据，可以直接用于后续数值计算。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 21}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.tools.format_measure", "project": "skfolio", "func": "format_measure", "origin_file": "skfolio/utils/tools.py", "test_list": ["tests/test_utils/test_tools.py"], "prob_info": {"func_start_lineno": 506, "func_end_lineno": 534, "key_block_start_lineno": 522, "key_block_end_lineno": 534, "new_func_code": "def format_measure(x: float, percent: bool = False) -> str:\n    \"\"\"Format a measure number into a user-friendly string.\n\n    Parameters\n    ----------\n    x : float\n        Number to format.\n\n    percent : bool, default=False\n        If this is set to True, the number is formatted in percentage.\n\n    Returns\n    -------\n    formatted : str\n        Formatted string.\n    \"\"\"\n# 本段代码的功能解释：\n#1. **目的**  \n#    将一个浮点数`x`格式化为用户友好的字符串表达形式。如果`percent`为True，则以百分比显示结果，否则以普通浮点数显示。该格式化会根据数值`x`的大小，智能确定小数点位数。\n#\n#2. **逻辑**  \n#    - 首先判断`x`是否为NaN（缺失值）。如果是，则直接返回其字符串表示，不做格式化。\n#    - 如果`percent`为True：\n#        - 令`xn = x * 100`（将数值转换为百分比表示），\n#        - 设置格式化符号`f = \"%\"`.\n#      否则：\n#        - 令`xn = x`（保持原值），\n#        - 设置格式化符号`f = \"f\"`（普通浮点格式）。\n#    - 判断`xn`是否为0：\n#        - 如果为0，则小数点位数`n = 0`。\n#        - 否则，调用`optimal_rounding_decimals(xn)`函数自适应决定保留小数点后n位。\n#          - 公式：  \n#            $$\n#            n = \n#            \\begin{cases}\n#            0, & xn = 0 \\\\\n#            \\texttt{optimal\\_rounding\\_decimals}(xn), & xn \\neq 0\n#            \\end{cases}\n#            $$\n#    - 最后，利用Python格式化字符串`\"{value:{fmt}}\"`，格式化参数`fmt`为`f\".{n}{f}\"`，即保留n位小数，格式类型为`f`（浮点）或`%`（百分比），返回格式化后的字符串。\n#\n#    条件分支总结：  \n#    - `if np.isnan(x):`：返回`x`的字符串，不做数值格式化。  \n#    - `if percent:`：决定是否做百分比缩放、用`%`格式化。  \n#    - `if xn == 0:`：控制保留小数位数为0，其它情况根据`optimal_rounding_decimals`调整。\n#\n#3. **异常**  \n#    无\n#\n#4. **变量赋值**\n#    - `xn`：  \n#        - 功能：根据`percent`参数，决定是用原始值还是转换为百分比的值（`x`或`x * 100`）。\n#        - 作用：用于后续确定小数点位数和格式化输出。\n#    - `f`：  \n#        - 功能：格式化符号，决定结果使用浮点型输出（`f`）或百分比输出（`%`）。\n#        - 作用：传递给格式化字符串，影响输出表现。\n#    - `n`：  \n#        - 功能：决定保留的小数位位数，0或自适应计算。\n#        - 作用：保证输出的字符串既美观又数值精度适中。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 21}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.tools.bisection", "project": "skfolio", "func": "bisection", "origin_file": "skfolio/utils/tools.py", "test_list": ["tests/test_utils/test_tools.py"], "prob_info": {"func_start_lineno": 553, "func_end_lineno": 570, "key_block_start_lineno": 566, "key_block_end_lineno": 570, "new_func_code": "def bisection(x: list[np.ndarray]) -> Iterator[list[np.ndarray, np.ndarray]]:\n    \"\"\"Generator to bisect a list of array.\n\n    Parameters\n    ----------\n    x : list[ndarray]\n        A list of array.\n\n    Yields\n    ------\n    arr :  Iterator[list[ndarray, ndarray]]\n        Bisected array.\n    \"\"\"\n# 本段代码的功能解释：\n#1. **目的**  \n#    将输入列表 `x` 里的每个元素（二级数组或类似对象）进行二分分割，为长度大于1的每个元素产生其前半段和后半段的两个子数组（或子列表），以便做进一步递归或分治处理。本代码块作为`bisection`生成器函数的主体，负责单步二分生成。\n#\n#2. **逻辑**  \n#    - 遍历输入列表 `x` 中的每个元素`e`。\n#    - 计算当前元素的长度`n = len(e)`。\n#    - 对每个元素，判断其长度是否大于1（`if n > 1`）：\n#        - 若条件成立，则：\n#            - 计算中间索引`mid = n // 2`。\n#            - 切片分割：`e[0:mid]`为前半部分，`e[mid:n]`为后半部分。\n#            - 使用`yield`返回包含2个子数组（或子列表）的列表：`[e[0:mid], e[mid:n]]`。\n#        - 若条件不成立（`n <= 1`），直接跳过不处理，不 yield。\n#    - 数学形式：\n#        - 若 `len(e)>1`，则将`e`分割为\n#          $$\n#          \\mathrm{left} = e[0:\\mathrm{mid}],\\quad \\mathrm{right} = e[\\mathrm{mid}:n], \\quad\\text{其中 } \\mathrm{mid} = \\lfloor n/2 \\rfloor\n#          $$\n#        - 并 yield `[left, right]`。\n#\n#3. **异常**  \n#    无\n#\n#4. **变量赋值**\n#    无（本代码块仅产生 yield，没有显式持久化赋值，且变量列表为空）\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 21}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.tools.safe_split", "project": "skfolio", "func": "safe_split", "origin_file": "skfolio/utils/tools.py", "test_list": ["tests/test_utils/test_tools.py"], "prob_info": {"func_start_lineno": 222, "func_end_lineno": 261, "key_block_start_lineno": 256, "key_block_end_lineno": 261, "new_func_code": "def safe_split(\n    X: npt.ArrayLike,\n    y: npt.ArrayLike | None = None,\n    indices: np.ndarray | None = None,\n    axis: int = 0,\n):\n    \"\"\"Create subset of dataset.\n\n    Slice X, y according to indices for cross-validation.\n\n    Parameters\n    ----------\n    X : array-like\n        Data to be indexed.\n\n    y : array-like\n        Data to be indexed.\n\n    indices : ndarray of int, optional\n        Rows or columns to select from X and y.\n        The default (`None`) is to select the entire data.\n\n    axis : int, default=0\n        The axis along which `X` will be sub-sampled. `axis=0` will select\n        rows while `axis=1` will select columns.\n\n    Returns\n    -------\n    X_subset : array-like\n        Indexed data.\n\n    y_subset : array-like\n        Indexed targets.\n    \"\"\"\n# 本段代码的功能解释：\n#1. **目的**  \n#    根据给定的`indices`和`axis`，对输入的数据`X`（以及可选的标签`y`）进行切片，生成其在指定维度的子集。在当前函数中，该代码块用于为交叉验证或子集选择构造新的数据、标签对。\n#\n#2. **逻辑**  \n#    - 首先，通过调用`saf​​e_indexing(X, indices=indices, axis=axis)`获得`X`的子集，赋值给`X_subset`。\n#    - 接着判断`y`是否为`None`：\n#        - 如果`y`不为`None`，则同样通过`saf​​e_indexing(y, indices=indices, axis=axis)`获得`y`的子集，赋值给`y_subset`。\n#        - 如果`y`为`None`，则`y_subset = None`。\n#    - 返回处理得到的`X_subset`和`y_subset`。\n#\n#3. **异常**  \n#    无。  \n#\n#4. **变量赋值**  \n#    - `X_subset`：表示对`X`沿指定`axis`选定`indices`后的数据子集。\n#    - `y_subset`：如果`y`不为`None`，则为对`y`沿指定`axis`选定`indices`后的标签子集；如果`y`为`None`，则为`None`。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 21}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.tools.deduplicate_names", "project": "skfolio", "func": "deduplicate_names", "origin_file": "skfolio/utils/tools.py", "test_list": ["tests/test_utils/test_tools.py"], "prob_info": {"func_start_lineno": 704, "func_end_lineno": 726, "key_block_start_lineno": 719, "key_block_end_lineno": 725, "new_func_code": "def deduplicate_names(names: npt.ArrayLike) -> list[str]:\n    \"\"\"Rename duplicated names by appending \"_{duplicate_nb}\" at the end.\n\n    This function is inspired by the pandas function `_maybe_dedup_names`.\n\n    Parameters\n    ----------\n    names : array-like of shape (n_names,)\n        List of names.\n\n    Returns\n    -------\n    names : list[str]\n        Deduplicate names.\n    \"\"\"\n# 本段代码的功能解释：\n#1. **目的**  \n#    对输入的名称列表去重，如果有重复的名称，则在它们后面依次增加后缀“_1”、“_2”等，保证输出列表中所有名称唯一。此代码块的作用是实现这个重命名操作，是`deduplicate_names`函数的核心逻辑。\n#\n#2. **逻辑**  \n#    - 首先将`names`转换为列表（确保可以按索引修改）。\n#    - 初始化一个空字典`counts`，用于统计每个名称出现的次数。\n#    - 依次遍历`names`列表，对每一个名称`col`：\n#        - 查询`counts`中`col`出现的次数，赋值给`cur_count`。如果该名称尚未出现，则为0。\n#        - 如果`cur_count > 0`，说明该名称已经出现过，要进行重命名：  \n#          - 将`names[i]`设为`f\"{col}_{cur_count}\"`，即在该名称后加上出现次数的后缀。\n#        - 更新`counts`字典，加1：  \n#          -  \n#            $$\n#            counts[col] = cur\\_count + 1\n#            $$\n#    - 这样，每个重复的名称都会依次加后缀，输出所有名称唯一的列表。\n#\n#    - 条件分支分析：  \n#      - `if cur_count > 0`：如果当前名称之前出现过（出现次数大于0），则为其追加重复编号后缀。\n#\n#3. **异常**  \n#    无\n#\n#4. **变量赋值**\n#    - `names`：被处理成去重且唯一的名称列表，每个重复项带有`_{重复次数}`后缀。\n#    - `counts`：用于记录每个名称出现的次数，辅助重命名，在函数返回时仅用于内部处理，不返回。\n<complete code here>\n    return names", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 21}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.tools.validate_input_list", "project": "skfolio", "func": "validate_input_list", "origin_file": "skfolio/utils/tools.py", "test_list": ["tests/test_utils/test_tools.py"], "prob_info": {"func_start_lineno": 445, "func_end_lineno": 503, "key_block_start_lineno": 479, "key_block_end_lineno": 503, "new_func_code": "def validate_input_list(\n    items: list[int | str],\n    n_assets: int,\n    assets_names: np.ndarray[str] | None,\n    name: str,\n    raise_if_string_missing: bool = True,\n) -> list[int]:\n    \"\"\"Convert a list of items (asset indices or asset names) into a list of\n    validated asset indices.\n\n    Parameters\n    ----------\n    items : list[int | str]\n       List of asset indices or asset names.\n\n    n_assets : int\n       Expected number of assets.\n       Used for verification.\n\n    assets_names : ndarray, optional\n       Asset names used when `items` contain strings.\n\n    name : str\n       Name of the items used for error messages.\n\n    raise_if_string_missing : bool, default=True\n        If set to True, raises an error if an item string is missing from assets_names;\n        otherwise, issue a User Warning.\n\n    Returns\n    -------\n    values : list[int]\n       Converted and validated list.\n    \"\"\"\n# 本段代码的功能解释：\n#1. **目的**  \n#    将输入的资产列表（可以是资产名或资产索引）统一转换为有效的资产索引列表，并验证其合法性，保证没有重复、所有资产均存在于资产集合中。此代码块在函数中负责检查输入、类型转换和异常处理，是资产索引标准化的核心环节。\n#\n#2. **逻辑**  \n#    - 首先检查`items`中是否有重复项：\n#        - 如果有重复，则抛出`ValueError`异常。\n#    - 构建可用资产索引集合`asset_indices = set(range(n_assets))`，以及结果列表`res`。\n#    - 逐一遍历`items`中的每个`asset`：\n#        - 如果`asset`为字符串类型（资产名）：\n#            - 如果`assets_names`为`None`，说明缺少资产名信息，抛出`ValueError`。\n#            - 生成布尔掩码`mask = assets_names == asset`，检查此资产名是否在`assets_names`中。\n#                - 如果存在（`np.any(mask)`为`True`），则找到该资产名对应的索引，并加入到`res`：  \n#                  $$ \\text{res.append}\\left(\\text{int}\\left(\\text{np.where(mask)[0][0]}\\right)\\right) $$\n#                - 如果不存在，且参数`raise_if_string_missing`为`True`，抛出`ValueError`；否则，发出`warnings.warn`警告。\n#        - 如果`asset`为整数（资产索引）：\n#            - 判断该索引是否在`asset_indices`集合内，如不在则抛出`ValueError`。\n#            - 若在，则将该索引转为整数并加入结果列表：`res.append(int(asset))`。\n#    - 最后返回转换和检查后的索引列表`res`。\n#\n#3. **异常**  \n#    - `ValueError`:  \n#        - 如果`items`中出现重复项；\n#        - 如果传入字符串类型资产但`assets_names`为`None`；\n#        - 如果资产名不在`assets_names`中且`raise_if_string_missing=True`；\n#        - 如果资产索引不在合法范围`asset_indices`中。\n#    - 另外，在资产名未找到且`raise_if_string_missing=False`时，会通过`warnings.warn`发出警告（非异常）。\n#\n#4. **变量赋值**\n#    - `res`：类型为`list[int]`，按顺序存储验证合格的资产索引，最终得到的即是符合要求的资产索引列表，返回用于后续资产访问或运算。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 21}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.sorting.dominate", "project": "skfolio", "func": "dominate", "origin_file": "skfolio/utils/sorting.py", "test_list": ["tests/test_utils/test_sorting.py"], "prob_info": {"func_start_lineno": 12, "func_end_lineno": 40, "key_block_start_lineno": 35, "key_block_end_lineno": 40, "new_func_code": "def dominate(fitness_1: np.ndarray, fitness_2: np.ndarray) -> bool:\n    \"\"\"Compute the domination of two fitness arrays.\n\n    Domination of `fitness_1` over `fitness_2` means that each objective (value) of\n    `fitness_1` is not strictly worse than the corresponding objective of `fitness_2`\n    and at least one objective is strictly better.\n\n    Parameters\n    ----------\n    fitness_1 : ndarray of floats of shape (n_objectives,)\n        Fitness array 1.\n\n    fitness_2 : ndarray of floats of shape (n_objectives,)\n        Fitness array 2.\n\n    Returns\n    -------\n    is_dominated : bool\n        Ture if `fitness_1` dominates `fitness_2`, False otherwise.\n    \"\"\"\n    if fitness_1.ndim != fitness_2.ndim != 1:\n        raise ValueError(\"fitness_1 and fitness_2 must be 1D array\")\n    not_equal = False\n# 本段代码的功能解释：\n#1. **目的**\n#   判断一个多目标适应度数组`fitness_1`是否支配另一个数组`fitness_2`，即判断在所有目标上，`fitness_1`是否全部不比`fitness_2`差且至少在一个目标上更优。该代码块是`dominate`函数的核心，用于逐一比较两个适应度向量的各项指标，保证支配定义的正确实现。\n#\n#2. **逻辑**\n#   - 使用`zip(fitness_1, fitness_2, strict=True)`按顺序配对遍历两个适应度数组的所有对应元素。\n#   - 对于每一对元素`self_value`, `other_value`：\n#       - 如果`self_value > other_value`，说明`fitness_1`在此目标上更优，设置`not_equal = True`以标记至少存在一个更优项。\n#       - 如果`self_value < other_value`，则`fitness_1`在此目标上劣于`fitness_2`，不满足支配条件，立即返回`False`。\n#   - 如果循环结束都没有发现`fitness_1`劣于`fitness_2`的目标，则返回`not_equal`，即只有在至少存在一个更优目标时才为`True`。\n#   - 变量更新关系如下：\n#     - 若存在 $self\\_value > other\\_value$：$\\texttt{not\\_equal} = \\texttt{True}$\n#     - 若存在 $self\\_value < other\\_value$：直接返回 $\\texttt{False}$\n#\n#3. **异常**\n#   无\n#\n#4. **变量赋值**\n#   - `not_equal`：用于标记在所有目标比较中，`fitness_1`是否至少在某个目标上严格优于`fitness_2`，最终决定支配关系的成立与否。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 2}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.sorting.non_denominated_sort", "project": "skfolio", "func": "non_denominated_sort", "origin_file": "skfolio/utils/sorting.py", "test_list": ["tests/test_utils/test_sorting.py"], "prob_info": {"func_start_lineno": 43, "func_end_lineno": 118, "key_block_start_lineno": 82, "key_block_end_lineno": 116, "new_func_code": "def non_denominated_sort(\n    fitnesses: np.ndarray, first_front_only: bool\n) -> list[list[int]]:\n    \"\"\"Fast non-dominated sorting.\n\n    Sort the fitnesses into different non-domination levels.\n    Complexity O(MN^2) where M is the number of objectives and N the number of\n    portfolios.\n\n    Parameters\n    ----------\n    fitnesses: ndarray of shape(n, n_fitness)\n        Fitnesses array.\n\n    first_front_only : bool\n        If this is set to True, only the first front is computed and returned.\n\n    Returns\n    -------\n    fronts: list[list[int]]\n      A list of Pareto fronts (lists), the first list includes non-dominated fitnesses.\n    \"\"\"\n    n = len(fitnesses)\n    fronts = []\n    if n == 0:\n        return fronts\n\n    # final rank that will be returned\n    n_ranked = 0\n    ranked = np.array([0 for _ in range(n)])\n\n    # for each portfolio a list of all portfolios that are dominated by this one\n    is_dominating = [[x for x in range(0)] for _ in range(n)]\n\n    # storage for the number of solutions dominated this one\n    n_dominated = [0 for _ in range(n)]\n\n    current_front = [x for x in range(0)]\n\n# 本段代码的功能解释：\n#1. **目的**  \n#    实现快速非支配排序算法，将种群`fitnesses`中的所有个体按Pareto非支配级别进行分层。此代码块负责判定每个个体属于哪个Pareto前沿，并将每一层的索引集合组成最终的`fronts`返回，支持只返回第一前沿（即所有未被支配的解）。\n#\n#2. **逻辑**  \n#    - 外层for循环`for i in range(n)`依次枚举每个个体`i`。\n#        - 内层for循环`for j in range(i+1, n)`，对后续所有个体`j`与`i`两两比较。\n#            - 条件分支1：`if dominate(fitnesses[i], fitnesses[j])`\n#                - 若`i`支配`j`，则将`j`添加到`is_dominating[i]`（即被`i`支配的所有个体索引），并将`n_dominated[j]`加1。\n#            - 条件分支2（elif）：`elif dominate(fitnesses[j], fitnesses[i])`\n#                - 若`j`支配`i`，则将`i`添加到`is_dominating[j]`（被j支配的集合），并将`n_dominated[i]`加1。\n#        - 循环结束后，若某个个体`i`没有被任何其他解支配（`n_dominated[i] == 0`），则将其加入第一前沿`current_front`，并且`ranked[i]`设为1.0，`n_ranked`加1。\n#    - 第一前沿生成后，将`current_front`添加到`fronts`列表，如果只需第一前沿，则直接返回。\n#    - 若需全部分层，循环处理：\n#        - 只要`n_ranked < n`，不断寻找后续前沿。\n#        - 对`current_front`内每个个体`i`：依次遍历其`is_dominating[i]`中所有被支配的个体`j`。\n#            - 每访问一次，`n_dominated[j]`减1。\n#            - 若`n_dominated[j] == 0`，则`j`已移除所有支配者，说明`j`属于下一个前沿，将其加入`next_front`，并设置`ranked[j]=1.0`，`n_ranked`加1。\n#        - 完成一层后，将`next_front`加入`fronts`，同时更新`current_front = next_front`。\n#    - 循环迭代，直到所有个体均有层次分层。\n#\n#    相关变量更新公式：\n#    - 支配计数递增：  \n#      $$\n#      n\\_dominated[j] = n\\_dominated[j] + 1\n#      $$\n#    - 支配计数递减（摘出前沿成员时）：  \n#      $$\n#      n\\_dominated[j] = n\\_dominated[j] - 1\n#      $$\n#    - 当前已分层个数递增：  \n#      $$\n#      n\\_ranked = n\\_ranked + 1\n#      $$\n#\n#3. **异常**  \n#    无\n#\n#4. **变量赋值**\n#    - `is_dominating`：`is_dominating[i]`存储个体`i`所支配的所有其他个体（索引）的列表。\n#    - `n_dominated`：`n_dominated[i]`统计的是有多少个体支配了个体`i`。\n#    - `current_front`：当前轮次处于同一Pareto前沿（层级）的所有个体索引。\n#    - `fronts`：存储每一层（前沿）的索引集合，是所有Pareto前沿的列表。\n#    - `ranked`：`ranked[i]`记录个体`i`是否已被分配到某一前沿，取值为1.0时表示已处理。\n#    - `n_ranked`：统计当前已经分配到某一前沿的个体数量。\n#    - `next_front`：在除第一前沿外，每一轮迭代中用于收集即将被分层的个体索引。\n<complete code here>\n\n    return fronts", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 2}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
{"id": "skfolio.skfolio.utils.bootstrap.stationary_bootstrap", "project": "skfolio", "func": "stationary_bootstrap", "origin_file": "skfolio/utils/bootstrap.py", "test_list": ["tests/test_utils/test_bootstrap.py"], "prob_info": {"func_start_lineno": 68, "func_end_lineno": 118, "key_block_start_lineno": 103, "key_block_end_lineno": 118, "new_func_code": "def stationary_bootstrap(\n    returns: np.ndarray,\n    n_bootstrap_samples: int,\n    block_size: float | None = None,\n    seed: int | None = None,\n) -> np.ndarray:\n    \"\"\"Create `n_bootstrap_samples` samples from a multivariate return series via\n    stationary bootstrapping.\n\n    Parameters\n    ----------\n    returns: ndarray of shape (n_observations, n_assets)\n        The returns array.\n\n    n_bootstrap_samples: int\n        The number of bootstrap samples to generate.\n\n    block_size: float, optional\n        The block size.\n        If this is set to None, we estimate the optimal block size using Politis &\n        White algorithm for all individual asset and the median.\n\n    seed: int, optional\n        Random seed used to initialize the pseudo-random number generator\n\n    Returns\n    -------\n    value: ndarray\n           The sample returns of shape (reps, nb observations, nb assets)\n\n    \"\"\"\n    np.random.seed(seed=seed)\n    n_observations, n_assets = returns.shape\n    x = np.vstack((returns, returns))\n    # Loop over reps bootstraps\n# 本段代码的功能解释：\n#1. **目的**  \n#    本代码块用于根据stationary bootstrap方法生成自助采样（bootstrap）样本的索引矩阵，通过一定区块结构的采样索引，从原始数据`x`中抽取有时序依赖的样本，用于后续统计分析或模型训练。其核心职责是，在给定区块长度控制下，构建每次bootstrap重采样所用的观测索引序列，以体现时间序列数据中的依赖结构。\n#\n#2. **逻辑**  \n#    - 判断`block_size`是否为None：  \n#        - 若为None，则对每个资产（即`returns`的每一列）分别调用`optimal_block_size`，得到每列的最优区块长度，并取它们的中位数赋值给`block_size`。  \n#    - 使用`np.random.randint`生成形状为`(n_bootstrap_samples, n_observations)`的初始索引矩阵`indices`，每个元素为`[0, n_observations)`区间的整数，表示原始样本的行索引。  \n#    - 用`np.random.rand`生成同形状的布尔型矩阵`cond`，`cond[i, j]`为True的条件为：  \n#        $$\n#        \\text{cond}[i, j] = \\text{uniform}(0, 1) \\geq \\frac{1}{\\text{block\\_size}}\n#        $$\n#        这是stationary bootstrap的区块延续判据。  \n#    - 双重循环遍历每个bootstrap重采样和每个观测位置，从第二个观测（$j \\geq 1$）起：  \n#        - 若`cond[i, j]`为True，则：  \n#            $$\n#            \\text{indices}[i, j] = \\text{indices}[i, j-1] + 1\n#            $$\n#            即该位置采样索引为前一个位置基础上加一，表示区块延续。  \n#        - 若为False，则保持原初始化的随机索引，表示区块重新采样起点。  \n#    - 对所有`indices`元素，若其值大于`2 * n_observations`，则将该位置索引置为0：  \n#        $$\n#        \\text{indices}[\\text{indices} > 2 * n\\_observations] = 0\n#        $$\n#        此逻辑的含义是：在区块延续过程中，索引有可能超出原序列长度。将其置0可避免越界错误。选择`2 * n_observations`作为上限主要是为了保证在极端情况下索引不会指向远离样本区间的非法位置，但具体取值是稳健性处理，并非理论要求，目的是保证索引不会溢出原始观测区间。  \n#    - 返回`x[indices, :]`，即按上述生成的索引从原始数据`x`中抽取的自助采样样本。这里`x`为采样数据的实际来源，需保证其与`returns`等价，否则将导致下游数据不一致。\n#\n#3. **异常**  \n#    无\n#\n#4. **变量赋值**\n#    - `block_size`：如传入为None，则计算所有资产收益序列单独的最优区块长度，并取中位数作为整体的区块控制参数。\n#    - `indices`：二维数组，存储所有bootstrap样本在各观测位置对应的原始数据行索引。初值全随机，后续部分位置据stationary bootstrap规则做区块延续处理，若发生越界（大于`2 * n_observations`），则置为0，防止非法索引。\n#    - `cond`：布尔型二维数组，定义每一位置是否与前一区块相连（True则连，否则重新采样）。\n#    - `x`：数据源，实际用于采样的原始矩阵。注意，采样结果来自`x`，本代码逻辑假设其为`returns`的副本或本应与原`returns`一致。\n<complete code here>", "gen_model": "gpt4o"}, "pytest_info": {"total_num": 1}, "type": "Development", "language": "Python", "model_info": {"gen_model": "gpt4o", "rewrite_model": "", "debug_gen_model": ""}}
